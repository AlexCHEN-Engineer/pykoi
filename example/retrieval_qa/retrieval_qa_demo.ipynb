{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lingjiekong/Documents/github/cambioml/pykoi\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the root folder to the module search path\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Move two levels up (go to the parent directory of the parent directory)\n",
    "two_levels_up_directory = os.path.dirname(os.path.dirname(current_directory))\n",
    "\n",
    "print(two_levels_up_directory)\n",
    "\n",
    "sys.path.append(two_levels_up_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingjiekong/anaconda3/envs/pykoi-test/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingjiekong/anaconda3/envs/pykoi-test/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from milvus import default_server\n",
    "from pymilvus import connections, utility\n",
    "import os\n",
    "import pykoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2.2.12-lite\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"VECTORDB_PATH\"] = os.path.join(os.getcwd(), \"temp/vectordb\")\n",
    "\n",
    "default_server.set_base_dir(\"{}/milvus\".format(os.getenv(\"VECTORDB_PATH\")))\n",
    "default_server.cleanup()\n",
    "default_server.start()\n",
    "connections.connect(host=\"127.0.0.1\", port=19530)\n",
    "print(utility.get_server_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [35644]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before init\n",
      "after init\n",
      "Table contents after creating table:\n",
      "INFO:     127.0.0.1:54495 - \"GET / HTTP/1.1\" 304 Not Modified\n",
      "INFO:     127.0.0.1:54495 - \"GET /assets/index-9d416840.js HTTP/1.1\" 304 Not Modified\n",
      "INFO:     127.0.0.1:54496 - \"GET /assets/index-fd8bb80f.css HTTP/1.1\" 304 Not Modified\n",
      "INFO:     127.0.0.1:54496 - \"GET /components HTTP/1.1\" 200 OK\n",
      "[/retrieval/file/get]: getting files...\n",
      "INFO:     127.0.0.1:54496 - \"GET /retrieval/file/get HTTP/1.1\" 200 OK\n",
      "[/retrieval/file/upload]: upload files...\n",
      "[/retrieval/file/upload]: saving file Reflecting_on_Davos_2023.docx\n",
      "INFO:     127.0.0.1:54502 - \"POST /retrieval/file/upload HTTP/1.1\" 200 OK\n",
      "[/retrieval/vector_db/index]: indexing files...\n",
      "Indexing ['Reflecting_on_Davos_2023.docx']...\n",
      "Already indexed file names: {'Reflecting_on_Davos_2023.docx'}\n",
      "INFO:     127.0.0.1:54502 - \"POST /retrieval/vector_db/index HTTP/1.1\" 200 OK\n",
      "[/retrieval/file/get]: getting files...\n",
      "INFO:     127.0.0.1:54503 - \"GET /retrieval/file/get HTTP/1.1\" 200 OK\n",
      "[/retrieval/vector_db/get]: get embedding...\n",
      "INFO:     127.0.0.1:54504 - \"GET /retrieval/vector_db/get HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:54504 - \"GET /chat/qa_table/retrieve HTTP/1.1\" 200 OK\n",
      "[/retrieval]: model inference...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "INFO:     127.0.0.1:54508 - \"GET /retrieval/what%20are%20the%20three%20main%20themes HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [35644]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"DOC_PATH\"] = os.path.join(os.getcwd(), \"temp/docs\")\n",
    "os.environ[\"VECTORDB_PATH\"] = os.path.join(os.getcwd(), \"temp/vectordb\")\n",
    "MODEL_SOURCE = \"openai\"\n",
    "\n",
    "#####################################\n",
    "# Creating a retrieval QA component #\n",
    "#####################################\n",
    "# vector database\n",
    "vector_db = pykoi.VectorDbFactory.create(\n",
    "    model_source=MODEL_SOURCE, vector_db_name=\"milvus\")\n",
    "\n",
    "# retrieval model with vector database\n",
    "retrieval_model = pykoi.RetrievalFactory.create(\n",
    "    model_source=MODEL_SOURCE, vector_db=vector_db\n",
    ")\n",
    "\n",
    "# sql database\n",
    "database = pykoi.QuestionAnswerDatabase(debug=True)\n",
    "dashboard = pykoi.Dashboard(database=database)\n",
    "\n",
    "# Creating an OpenAI model\n",
    "model = pykoi.ModelFactory.create_model(\n",
    "    model_source=MODEL_SOURCE, api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# retrieval and chatbot components\n",
    "retriever = pykoi.RetrievalQA(retrieval_model=retrieval_model, vector_db=vector_db)\n",
    "chatbot = pykoi.Chatbot(model=model, feedback=\"vote\", is_retrieval=True)\n",
    "\n",
    "############################################################\n",
    "# Starting the application and retrieval qa as a component #\n",
    "############################################################\n",
    "# Create the application\n",
    "app = pykoi.Application(debug=False, share=False)\n",
    "app.add_component(retriever)\n",
    "app.add_component(chatbot)\n",
    "app.add_component(dashboard)\n",
    "app.run()\n",
    "default_server.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pykoi-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
