{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone from github\n",
    "# git clone https://github.com/CambioML/pykoi.git /home/ec2-user/SageMaker/pykoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1:\n",
    "# use github code as source\n",
    "import sys\n",
    "sys.path.append(\"/home/ec2-user/SageMaker/pykoi\")\n",
    "!pip install poetry\n",
    "!pip install -q nest_asyncio\n",
    "!poetry install --no-root\n",
    "!pip3 install torch --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Option 2:\n",
    "# # pip install pykoi into site-packages\n",
    "# !pip install -q nest_asyncio\n",
    "# !pip install pykoi\n",
    "# !pip3 install torch --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pykoi\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"create model...\")\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"tiiuae/falcon-7b\",\n",
    "    trust_remote_code=True,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "print(\"create tokenizer...\")\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"tiiuae/falcon-7b\",\n",
    "    trust_remote_code=True,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"create pykoi model component for UI...\")\n",
    "model = pykoi.chat.llm.huggingface.HuggingfaceModel.create(\n",
    "    model=hf_model,\n",
    "    tokenizer=hf_tokenizer,\n",
    "    name=\"falcon-7b\",\n",
    "    max_length=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pykoi.QuestionAnswerDatabase(debug=True)\n",
    "chatbot = pykoi.Chatbot(model=model, feedback=\"vote\")\n",
    "dashboard = pykoi.Dashboard(database=database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pykoi.Application(share=True)\n",
    "app.add_component(chatbot)\n",
    "app.add_component(dashboard)\n",
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
