{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/725a/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pykoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a database, model and chatbot\n",
    "\n",
    "To a launch a pykoi App, you only need to customize 3 components: a model, a database and a chatbot. Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_database = pykoi.QuestionAnswerDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HuggingfaceModel] loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HuggingfaceModel] loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "model = pykoi.ModelFactory.create_model(\n",
    "    model_source=\"huggingface\", \n",
    "    pretrained_model_name_or_path=\"tiiuae/falcon-7b\", ## TODO: Change pretrained_model_name_or_path to model_source\n",
    "    trust_remote_code=True, ## TODO: set as default\n",
    "    load_in_8bit=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = pykoi.Chatbot(model=model, feedback=\"vote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the App\n",
    "\n",
    "Now we can launch the chatbot using the model and database. Once you run the below line, you will see a Tunnel link which ends with `ngrok-free.app`. Click this link and you can see the below interface:\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"image/chatbot_rank.png\" width=\"75%\" height=\"75%\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "You may need to set a ngrok token (one time) by uncomment the below line, add your [personal ngrok token](https://dashboard.ngrok.com/get-started/your-authtoken) and run this `ngrok config` line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ngrok config add-authtoken xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t=2023-07-25T17:14:28+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/home/ubuntu/.config/ngrok/ngrok.yml legacy_path=/home/ubuntu/.ngrok2/ngrok.yml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: NgrokTunnel: \"https://a950-35-89-23-142.ngrok-free.app\" -> \"http://localhost:45853\"\n",
      " * Serving Flask app 'pykoi.application'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:45853\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [25/Jul/2023 17:14:32] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jul/2023 17:14:32] \"GET /assets/index-918eba54.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jul/2023 17:14:32] \"GET /assets/index-cf40d152.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jul/2023 17:14:33] \"GET /components HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jul/2023 17:14:33] \"GET /vite.svg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Jul/2023 17:14:33] \"\u001b[33mGET /chat/qa_table/retrieve HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [25/Jul/2023 17:14:33] \"\u001b[36mGET /vite.svg HTTP/1.1\u001b[0m\" 304 -\n",
      "/opt/conda/envs/725a/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HuggingfaceModel] encode...\n",
      "[HuggingfaceModel] generate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Jul/2023 17:15:25] \"POST /chat/Tell%20me%20what%20is%20a%20foundation%20model HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HuggingfaceModel] decode...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Jul/2023 17:15:54] \"POST /chat/qa_table/update HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping server...\n"
     ]
    }
   ],
   "source": [
    "app = pykoi.Application(debug=False, share=True)\n",
    "app.add_component(chatbot)\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize your data\n",
    "\n",
    "Once you collect enough data via the chatbot app above, you can visualize your data via the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dashboard = pykoi.Dashboard(database=qa_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'pykoi.application'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:59601\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "app = pykoi.Application(debug=False, share=False)\n",
    "app.add_component(chatbot)\n",
    "app.add_component(qa_dashboard)\n",
    "app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will only see one localhost link after you run the `app.run()` below. If you are on EC2 or a remote server, you can tunnel it back to your laptop via the following options:\n",
    "\n",
    "- If you are using VSCode, check [tunnel using VSCode](https://code.visualstudio.com/docs/remote/ssh#_forwarding-a-port-creating-ssh-tunnel);\n",
    "- [Directly config via EC2](https://www.opensourceforu.com/2021/09/how-to-do-reverse-tunnelling-with-the-amazon-ec2-instance/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0721",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
