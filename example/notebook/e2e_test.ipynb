{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lingjiekong/Documents/github/cambioml/pykoi\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the root folder to the module search path\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Move two levels up (go to the parent directory of the parent directory)\n",
    "two_levels_up_directory = os.path.dirname(os.path.dirname(current_directory))\n",
    "\n",
    "print(two_levels_up_directory)\n",
    "\n",
    "sys.path.append(two_levels_up_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /Users/lingjiekong/Library/Application Support/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!ngrok config add-authtoken xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_CSV_HEADER_ID = 'ID'\n",
    "QA_CSV_HEADER_QUESTION = 'Question'\n",
    "QA_CSV_HEADER_ANSWER = 'Answer'\n",
    "QA_CSV_HEADER_VOTE_STATUS = 'Vote Status'\n",
    "QA_CSV_HEADER_TIMESTAMPS = 'Timestamp'\n",
    "QA_CSV_HEADER = (\n",
    "    QA_CSV_HEADER_ID,\n",
    "    QA_CSV_HEADER_QUESTION,\n",
    "    QA_CSV_HEADER_ANSWER,\n",
    "    QA_CSV_HEADER_VOTE_STATUS,\n",
    "    QA_CSV_HEADER_TIMESTAMPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_database = pykoi.QuestionAnswerDatabase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Cambio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HuggingfaceModel] loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 950/950 [00:00<00:00, 3.03MB/s]\n",
      "Downloading (…)/configuration_RW.py: 100%|██████████| 2.61k/2.61k [00:00<00:00, 16.1MB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n",
      "- configuration_RW.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Downloading (…)main/modelling_RW.py: 100%|██████████| 47.6k/47.6k [00:00<00:00, 836kB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b:\n",
      "- modelling_RW.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m pykoi\u001b[39m.\u001b[39;49mModelFactory\u001b[39m.\u001b[39;49mcreate_model(\n\u001b[1;32m      2\u001b[0m     model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhuggingface\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m## TODO: Change model_name to model_source\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m     pretrained_model_name_or_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtiiuae/falcon-7b\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m## TODO: Change pretrained_model_name_or_path to model_name\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m## TODO: set as default\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m     load_in_8bit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/github/cambioml/pykoi/pykoi/llm/model_factory.py:49\u001b[0m, in \u001b[0;36mModelFactory.create_model\u001b[0;34m(model_name, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39melif\u001b[39;00m model_name \u001b[39m==\u001b[39m LlmName\u001b[39m.\u001b[39mHUGGINGFACE:\n\u001b[1;32m     47\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpykoi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhuggingface\u001b[39;00m \u001b[39mimport\u001b[39;00m HuggingfaceModel\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m HuggingfaceModel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     50\u001b[0m \u001b[39melif\u001b[39;00m model_name \u001b[39m==\u001b[39m LlmName\u001b[39m.\u001b[39mPEFT_HUGGINGFACE:\n\u001b[1;32m     51\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpykoi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mllm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpeft_huggingface\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftHuggingfacemodel\n",
      "File \u001b[0;32m~/Documents/github/cambioml/pykoi/pykoi/llm/huggingface.py:33\u001b[0m, in \u001b[0;36mHuggingfaceModel.__init__\u001b[0;34m(self, pretrained_model_name_or_path, trust_remote_code, load_in_8bit, max_length, device_map)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m# running on cpu can be slow!!!\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[HuggingfaceModel] loading model...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m     34\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m     35\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code,\n\u001b[1;32m     36\u001b[0m     load_in_8bit\u001b[39m=\u001b[39;49mload_in_8bit,\n\u001b[1;32m     37\u001b[0m     device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[HuggingfaceModel] loading tokenizer...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     41\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m     42\u001b[0m     trust_remote_code\u001b[39m=\u001b[39mtrust_remote_code,\n\u001b[1;32m     43\u001b[0m     load_in_8bit\u001b[39m=\u001b[39mload_in_8bit,\n\u001b[1;32m     44\u001b[0m     device_map\u001b[39m=\u001b[39mdevice_map,\n\u001b[1;32m     45\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:488\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m         \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mregister(config\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, model_class, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 488\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    489\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    492\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/transformers/modeling_utils.py:2277\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[39mif\u001b[39;00m load_in_8bit \u001b[39mor\u001b[39;00m load_in_4bit:\n\u001b[1;32m   2276\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_accelerate_available() \u001b[39mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[0;32m-> 2277\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m   2278\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2279\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2280\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m pip install bitsandbytes` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2281\u001b[0m         )\n\u001b[1;32m   2283\u001b[0m     \u001b[39mif\u001b[39;00m torch_dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2284\u001b[0m         \u001b[39m# We force the `dtype` to be float16, this is a requirement from `bitsandbytes`\u001b[39;00m\n\u001b[1;32m   2285\u001b[0m         logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m   2286\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOverriding torch_dtype=\u001b[39m\u001b[39m{\u001b[39;00mtorch_dtype\u001b[39m}\u001b[39;00m\u001b[39m with `torch_dtype=torch.float16` due to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2287\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2288\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mPass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2289\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m torch_dtype=torch.float16 to remove this warning.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2290\u001b[0m         )\n",
      "\u001b[0;31mImportError\u001b[0m: Using `load_in_8bit=True` requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes `pip install -i https://test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes` "
     ]
    }
   ],
   "source": [
    "model = pykoi.ModelFactory.create_model(\n",
    "    model_name=\"huggingface\", ## TODO: Change model_name to model_source\n",
    "    pretrained_model_name_or_path=\"tiiuae/falcon-7b\", ## TODO: Change pretrained_model_name_or_path to model_name\n",
    "    trust_remote_code=True, ## TODO: set as default\n",
    "    load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chatbot \u001b[39m=\u001b[39m pykoi\u001b[39m.\u001b[39mChatbot(model\u001b[39m=\u001b[39mmodel, feedback\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvote\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "chatbot = pykoi.Chatbot(model=model, feedback=\"vote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dashboard = pykoi.Dashboard(database=qa_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chatbot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m app \u001b[39m=\u001b[39m pykoi\u001b[39m.\u001b[39mApplication(debug\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, share\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m app\u001b[39m.\u001b[39madd_component(chatbot)\n\u001b[1;32m      3\u001b[0m app\u001b[39m.\u001b[39madd_component(qa_dashboard)\n\u001b[1;32m      4\u001b[0m app\u001b[39m.\u001b[39mrun()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chatbot' is not defined"
     ]
    }
   ],
   "source": [
    "app = pykoi.Application(debug=False, share=True)\n",
    "app.add_component(chatbot)\n",
    "app.add_component(qa_dashboard)\n",
    "app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RLHF using the data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q trl peft evaluate datasets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 5 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m my_data_pd \u001b[39m=\u001b[39m qa_database\u001b[39m.\u001b[39;49mretrieve_all_question_answers_as_pandas()\n\u001b[1;32m      2\u001b[0m my_data_pd\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Documents/github/cambioml/pykoi/pykoi/db/qa_database.py:165\u001b[0m, in \u001b[0;36mQuestionAnswerDatabase.retrieve_all_question_answers_as_pandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve_all_question_answers()\n\u001b[1;32m    164\u001b[0m rows_to_pd \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(rows)\n\u001b[0;32m--> 165\u001b[0m rows_to_pd\u001b[39m.\u001b[39;49mcolumns \u001b[39m=\u001b[39m QA_CSV_HEADER\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m rows_to_pd\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/pandas/core/generic.py:6002\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   6001\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[0;32m-> 6002\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name, value)\n\u001b[1;32m   6003\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m   6004\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/pandas/core/generic.py:730\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m labels \u001b[39m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 730\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mset_axis(axis, labels)\n\u001b[1;32m    731\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/pandas/core/internals/managers.py:225\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[39m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis] \u001b[39m=\u001b[39m new_labels\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39melif\u001b[39;00m new_len \u001b[39m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength mismatch: Expected axis has \u001b[39m\u001b[39m{\u001b[39;00mold_len\u001b[39m}\u001b[39;00m\u001b[39m elements, new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues have \u001b[39m\u001b[39m{\u001b[39;00mnew_len\u001b[39m}\u001b[39;00m\u001b[39m elements\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 5 elements"
     ]
    }
   ],
   "source": [
    "my_data_pd = qa_database.retrieve_all_question_answers_as_pandas()\n",
    "my_data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_data_pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m my_data_pd \u001b[39m=\u001b[39m my_data_pd[my_data_pd[QA_CSV_HEADER_VOTE_STATUS]\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mup\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m my_data_pd\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_data_pd' is not defined"
     ]
    }
   ],
   "source": [
    "my_data_pd = my_data_pd[my_data_pd[QA_CSV_HEADER_VOTE_STATUS]==\"up\"]\n",
    "my_data_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_data_pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[0;32m----> 3\u001b[0m my_data_pd \u001b[39m=\u001b[39m my_data_pd[[QA_CSV_HEADER_ID,\n\u001b[1;32m      4\u001b[0m                         QA_CSV_HEADER_QUESTION,\n\u001b[1;32m      5\u001b[0m                         QA_CSV_HEADER_ANSWER]]\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMy local database has \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m samples\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(my_data_pd\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]))\n\u001b[1;32m      7\u001b[0m dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_dict(my_data_pd)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_data_pd' is not defined"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "my_data_pd = my_data_pd[[QA_CSV_HEADER_ID,\n",
    "                        QA_CSV_HEADER_QUESTION,\n",
    "                        QA_CSV_HEADER_ANSWER]]\n",
    "print(\"My local database has {} samples\".format(my_data_pd.shape[0]))\n",
    "dataset = Dataset.from_dict(my_data_pd)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "meta-llama/Llama-2-7b-hf is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    262\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/transformers/utils/hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    418\u001b[0m         path_or_repo_id,\n\u001b[1;32m    419\u001b[0m         filename,\n\u001b[1;32m    420\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    421\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    422\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    423\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    424\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    425\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    426\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    427\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    428\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    430\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/huggingface_hub/file_download.py:1195\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1196\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1197\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1198\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1199\u001b[0m         timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m   1200\u001b[0m     )\n\u001b[1;32m   1201\u001b[0m \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[1;32m   1202\u001b[0m     \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/huggingface_hub/file_download.py:1541\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1532\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1533\u001b[0m     method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1534\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1539\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m   1540\u001b[0m )\n\u001b[0;32m-> 1541\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1543\u001b[0m \u001b[39m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:293\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[1;32m    286\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m make sure you are authenticated.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m     )\n\u001b[0;32m--> 293\u001b[0m     \u001b[39mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-64be1f5c-5726a5de44413b653759ddad;a6f28f78-63af-4af4-af85-8d2f0bb4385a)\n\nRepository Not Found for url: https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# from pykoi.rlhf.rlhf import RLHFConfig, SFT ##, RewardTrainer, RL\u001b[39;00m\n\u001b[1;32m      3\u001b[0m config \u001b[39m=\u001b[39m pykoi\u001b[39m.\u001b[39mRLHFConfig(base_model_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmeta-llama/Llama-2-7b-hf\u001b[39m\u001b[39m\"\u001b[39m, dataset_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlocal_db\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m rlhf_step1_sft \u001b[39m=\u001b[39m pykoi\u001b[39m.\u001b[39;49mSFT(config)\n",
      "File \u001b[0;32m~/Documents/github/cambioml/pykoi/pykoi/rlhf/rlhf.py:399\u001b[0m, in \u001b[0;36mSFT.__init__\u001b[0;34m(self, rlhf_config)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39mInitializes the SFTTrainer object.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \n\u001b[1;32m    395\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[39m    rlhf_config (RLHFConfig): The RLHF configuration object.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlhf_config \u001b[39m=\u001b[39m rlhf_config\n\u001b[0;32m--> 399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(rlhf_config\u001b[39m.\u001b[39;49mbase_model_path)\n\u001b[1;32m    400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_proc \u001b[39m=\u001b[39m (\n\u001b[1;32m    401\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlhf_config\u001b[39m.\u001b[39mnum_workers \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlhf_config\u001b[39m.\u001b[39mstreaming \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    402\u001b[0m )\n\u001b[1;32m    403\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_datasets(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlhf_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:652\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    651\u001b[0m \u001b[39m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m tokenizer_config \u001b[39m=\u001b[39m get_tokenizer_config(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    653\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    654\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m tokenizer_config[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:496\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39mLoads the tokenizer configuration from a pretrained model tokenizer configuration.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39mtokenizer_config = get_tokenizer_config(\"tokenizer-test\")\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39m```\"\"\"\u001b[39;00m\n\u001b[1;32m    495\u001b[0m commit_hash \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 496\u001b[0m resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    497\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m    498\u001b[0m     TOKENIZER_CONFIG_FILE,\n\u001b[1;32m    499\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    500\u001b[0m     force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    501\u001b[0m     resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    502\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    503\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    504\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    505\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    506\u001b[0m     subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    507\u001b[0m     _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    508\u001b[0m     _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    509\u001b[0m     _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    510\u001b[0m )\n\u001b[1;32m    511\u001b[0m \u001b[39mif\u001b[39;00m resolved_config_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    512\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/plotano/lib/python3.10/site-packages/transformers/utils/hub.py:433\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    418\u001b[0m         path_or_repo_id,\n\u001b[1;32m    419\u001b[0m         filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[1;32m    430\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m--> 433\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    434\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m     )\n\u001b[1;32m    439\u001b[0m \u001b[39mexcept\u001b[39;00m RevisionNotFoundError:\n\u001b[1;32m    440\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mrevision\u001b[39m}\u001b[39;00m\u001b[39m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfor this model name. Check the model page at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for available revisions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: meta-llama/Llama-2-7b-hf is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "# from pykoi.rlhf.rlhf import RLHFConfig, SFT ##, RewardTrainer, RL\n",
    "\n",
    "config = pykoi.RLHFConfig(base_model_path=\"meta-llama/Llama-2-7b-hf\", dataset_type=\"local_db\")\n",
    "\n",
    "rlhf_step1_sft = pykoi.SFT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rlhf_step1_sft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rlhf_step1_sft\u001b[39m.\u001b[39mtrain_and_save(\u001b[39m\"\u001b[39m\u001b[39m../../rlhf_tests/step1_07211538\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rlhf_step1_sft' is not defined"
     ]
    }
   ],
   "source": [
    "rlhf_step1_sft.train_and_save(\"../../rlhf_tests/step1_07211538\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert my data to the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Vote Status</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Who is Rachel?</td>\n",
       "      <td>CEO of CambioML</td>\n",
       "      <td>up</td>\n",
       "      <td>2023-07-20 23:19:25.202246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Who is Jared?</td>\n",
       "      <td>CTO of CambioML</td>\n",
       "      <td>up</td>\n",
       "      <td>2023-07-20 23:19:25.206972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Who is Kimi?</td>\n",
       "      <td>Nobody of CambioML</td>\n",
       "      <td>down</td>\n",
       "      <td>2023-07-20 23:19:25.210210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12891264</td>\n",
       "      <td>I am using jQuery fileupload plugin and I want...</td>\n",
       "      <td>Looking at the library code, seems all events ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>588860</td>\n",
       "      <td>When reading about the Big Bang you’ll commonl...</td>\n",
       "      <td>No. The local energy *density* is reduced as t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>16617081</td>\n",
       "      <td>here is my object with sample data\\n\\n```\\nObj...</td>\n",
       "      <td>Firstly, if you've just got a date, I would su...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>7690401</td>\n",
       "      <td>Trying to add \"import\" statement to my new sca...</td>\n",
       "      <td>Make sure that you have a Java SDK configured ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>42071634</td>\n",
       "      <td>Is there any way to define a static method in ...</td>\n",
       "      <td>The simplest solution is probably to have the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>42071634</td>\n",
       "      <td>Is there any way to define a static method in ...</td>\n",
       "      <td>The simplest solution is probably to have the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>42071634</td>\n",
       "      <td>Is there any way to define a static method in ...</td>\n",
       "      <td>The simplest solution is probably to have the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                           Question  \\\n",
       "0          1                                     Who is Rachel?   \n",
       "1          2                                      Who is Jared?   \n",
       "2          3                                       Who is Kimi?   \n",
       "0   12891264  I am using jQuery fileupload plugin and I want...   \n",
       "1     588860  When reading about the Big Bang you’ll commonl...   \n",
       "..       ...                                                ...   \n",
       "92  16617081  here is my object with sample data\\n\\n```\\nObj...   \n",
       "93   7690401  Trying to add \"import\" statement to my new sca...   \n",
       "94  42071634  Is there any way to define a static method in ...   \n",
       "95  42071634  Is there any way to define a static method in ...   \n",
       "96  42071634  Is there any way to define a static method in ...   \n",
       "\n",
       "                                               Answer Vote Status  \\\n",
       "0                                     CEO of CambioML          up   \n",
       "1                                     CTO of CambioML          up   \n",
       "2                                  Nobody of CambioML        down   \n",
       "0   Looking at the library code, seems all events ...         NaN   \n",
       "1   No. The local energy *density* is reduced as t...         NaN   \n",
       "..                                                ...         ...   \n",
       "92  Firstly, if you've just got a date, I would su...         NaN   \n",
       "93  Make sure that you have a Java SDK configured ...         NaN   \n",
       "94  The simplest solution is probably to have the ...         NaN   \n",
       "95  The simplest solution is probably to have the ...         NaN   \n",
       "96  The simplest solution is probably to have the ...         NaN   \n",
       "\n",
       "                     Timestamp  \n",
       "0   2023-07-20 23:19:25.202246  \n",
       "1   2023-07-20 23:19:25.206972  \n",
       "2   2023-07-20 23:19:25.210210  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "..                         ...  \n",
       "92                         NaN  \n",
       "93                         NaN  \n",
       "94                         NaN  \n",
       "95                         NaN  \n",
       "96                         NaN  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "my_stackoverflow_dataset = pd.read_csv(\"/home/ubuntu/pykoi/pykoi/my_sql_data.csv\", index_col=0)\n",
    "my_stackoverflow_dataset.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in my_stackoverflow_dataset.iloc[3:100].to_dict('records'):\n",
    "    qa_id = qa_database.insert_question_answer(question=row[QA_CSV_HEADER_QUESTION],\n",
    "                                       answer=row[QA_CSV_HEADER_ANSWER])\n",
    "    qa_database.update_vote_status(id=qa_id, vote_status=\"up\") #row[QA_CSV_HEADER_VOTE_STATUS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset.from_dict(my_data_pd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0721",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
