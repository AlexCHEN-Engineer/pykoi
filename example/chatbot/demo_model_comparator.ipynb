{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/goldpiggy/git/pykoi\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the root folder to the module search path\n",
    "# Get the current directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Move two levels up (go to the parent directory of the parent directory)\n",
    "two_levels_up_directory = os.path.dirname(os.path.dirname(current_directory))\n",
    "\n",
    "print(two_levels_up_directory)\n",
    "\n",
    "sys.path.append(two_levels_up_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goldpiggy/anaconda3/envs/0731a/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/goldpiggy/anaconda3/envs/0731a/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import pykoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: LLMs Comparison\n",
    "\n",
    "`pykoi` provides simple API to compare between LLMs, including your own finetuned LLM, a pretrained LLM from huggingface, or OpenAI/Anthropic/Bedrock APIs.\n",
    "\n",
    "This demo shows how to create and launch an LLM comparison app. Let's get started!\n",
    "\n",
    "## Load LLMs\n",
    "\n",
    "#### 1. Creating an OpenAI model (requires an OpenAI API key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter openai api key here\n",
    "api_key = \"\"\n",
    "\n",
    "# Creating an OpenAI model\n",
    "openai_model_1 = pykoi.ModelFactory.create_model(\n",
    "    model_source=\"openai\", api_key=api_key, engine=\"babbage\"\n",
    ")\n",
    "openai_model_2 = pykoi.ModelFactory.create_model(\n",
    "    model_source=\"openai\", api_key=api_key, engine=\"curie\"\n",
    ")\n",
    "openai_model_3 = pykoi.ModelFactory.create_model(\n",
    "    model_source=\"openai\", api_key=api_key, engine=\"davinci\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Creating a Huggingface model (requires at least EC2 `g4.2xlarge` or GPU with 16G memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## requires a GPU with at least 16GB memory (e.g. g4.2xlarge)\n",
    "# huggingface_model = pykoi.ModelFactory.create_model(\n",
    "#     model_source=\"huggingface\",\n",
    "#     pretrained_model_name_or_path=\"databricks/dolly-3b\",\n",
    "# )\n",
    "\n",
    "# ## requires a GPU with at least 24GB memory (e.g. g5.2xlarge)\n",
    "# huggingface_model = pykoi.ModelFactory.create_model(\n",
    "#     model_source=\"huggingface\",\n",
    "#     pretrained_model_name_or_path=\"tiiuae/falcon-7b\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a chatbot comparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in a list of models to compare\n",
    "chatbot_comparator = pykoi.Compare(models=[openai_model_1, openai_model_2])\n",
    "chatbot_comparator.add(openai_model_3)\n",
    "\n",
    "# or add models later\n",
    "# chatbot_comparator.add(huggingface_model)\n",
    "# chatbot_comparator.add(peft_huggingface_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pykoi.Application(debug=False, share=False)\n",
    "app.add_component(chatbot_comparator)\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0731a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
