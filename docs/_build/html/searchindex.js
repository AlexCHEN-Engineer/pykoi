Search.setIndex({"docnames": ["demo", "index", "installation", "modules", "pykoi", "pykoi.component", "pykoi.db", "pykoi.llm", "pykoi.rlhf", "tutorial"], "filenames": ["demo.rst", "index.rst", "installation.rst", "modules.rst", "pykoi.rst", "pykoi.component.rst", "pykoi.db.rst", "pykoi.llm.rst", "pykoi.rlhf.rst", "tutorial.rst"], "titles": ["Quick Tour", "Welcome to pykoi\u2019s documentation!", "Getting Started", "pykoi", "pykoi package", "pykoi.component package", "pykoi.db package", "pykoi.llm package", "pykoi.rlhf package", "Getting Started"], "terms": {"packag": [1, 3], "index": 1, "modul": [1, 3], "search": 1, "page": 1, "subpackag": [1, 3], "compon": [1, 3, 4], "submodul": [1, 3], "base": [3, 4, 6, 7, 8], "chatbot_database_factori": [3, 4], "constant": [3, 4], "content": 3, "db": [1, 3, 4, 8], "qa_databas": [3, 4], "ranking_databas": [3, 4], "llm": [1, 3, 4], "abs_llm": [3, 4], "huggingfac": [3, 4], "model_factori": [3, 4], "openai": [3, 4], "peft_huggingfac": [3, 4], "rlhf": [1, 3, 4], "applic": [1, 3], "add_compon": [3, 4], "create_chatbot_rout": [3, 4], "create_feedback_rout": [3, 4], "run": [3, 4], "find_free_port": [1, 3, 4], "state": [1, 3], "store": [1, 3, 4, 6], "count": [3, 4], "decrement": [3, 4], "hello": [3, 4], "increment": [3, 4], "name": [3, 4, 5, 6, 7], "chatbot": [4, 5], "model": [4, 5, 7, 8], "databas": [0, 1, 2, 4, 5, 6, 9], "id": [4, 5, 6], "data_sourc": [4, 5], "svelte_compon": [4, 5], "prop": [4, 5], "dashboard": [4, 5], "datasourc": [4, 5], "fetch_func": [4, 5], "dropdown": [4, 5], "value_column": [4, 5], "chatbotdatabasefactori": [4, 5], "creat": [0, 1, 2, 4, 5, 6, 7, 9], "feedbacktyp": [4, 5], "rank": [4, 5, 6], "vote": [4, 5, 6], "questionanswerdatabas": [4, 5, 6], "close_connect": [4, 6], "create_t": [4, 6], "get_connect": [4, 6], "get_cursor": [4, 6], "insert_question_answ": [4, 6], "print_tabl": [4, 6], "retrieve_all_question_answ": [4, 6], "retrieve_all_question_answers_as_panda": [4, 6], "save_to_csv": [4, 6], "update_vote_statu": [4, 6], "rankingdatabas": [4, 5, 6], "insert_rank": [4, 6], "absllm": [4, 5, 7], "none": [4, 5, 7, 8], "predict": [4, 7], "modelsourc": [4, 7], "huggingfacemodel": [4, 7], "modelfactori": [4, 7], "create_model": [4, 7], "openaimodel": [4, 7], "_engin": [4, 7], "_max_token": [4, 7], "_temperatur": [4, 7], "pefthuggingfacemodel": [4, 7], "_model": [4, 7], "_token": [4, 7], "_max_length": [4, 7], "rlhfconfig": [4, 8], "adafactor": [4, 8], "adap_kl_ctrl": [4, 8], "answer_titl": [4, 8], "base_model_path": [4, 7, 8], "bf16": [4, 8], "dataset_eval_fold": [4, 8], "dataset_nam": [4, 8], "dataset_reward_fold": [4, 8], "dataset_subset_rl": [4, 8], "dataset_subset_rl_train": [4, 8], "dataset_subset_sft": [4, 8], "dataset_subset_sft_train": [4, 8], "dataset_typ": [4, 8], "deepspe": [4, 8], "device_map": [4, 7, 8], "do_sampl": [4, 8], "early_stop": [4, 8], "eos_token_id": [4, 8], "eval_freq": [4, 8], "evaluation_strategi": [4, 8], "fp16": [4, 8], "gradient_accumulation_step": [4, 8], "gradient_checkpoint": [4, 8], "init_kl_coef": [4, 8], "label_nam": [4, 8], "learning_r": [4, 8], "load_in_8bit": [4, 7, 8], "local_rank": [4, 8], "log_freq": [4, 8], "logging_step": [4, 8], "logging_strategi": [4, 8], "lora_config_reward": [4, 8], "lora_config_rl": [4, 8], "lr_scheduler_type_sft": [4, 8], "max_seq_length": [4, 8], "max_seq_length_reward": [4, 8], "max_step": [4, 8], "mini_batch_s": [4, 8], "num_warmup_step": [4, 8], "num_work": [4, 8], "output_dir": [4, 8], "output_max_length": [4, 8], "per_device_eval_batch_s": [4, 8], "per_device_train_batch_s": [4, 8], "ppo_batch_s": [4, 8], "ppo_epoch": [4, 8], "push_to_hub": [4, 8], "question_titl": [4, 8], "remove_unused_column": [4, 8], "resume_from_checkpoint": [4, 8], "reward_baselin": [4, 8], "reward_epoch": [4, 8], "reward_lora_path": [4, 8], "reward_merged_path": [4, 8], "reward_model_path": [4, 8], "reward_num_of_data": [4, 8], "save_freq": [4, 8], "seed": [4, 8], "sft_lora_path": [4, 8], "sft_merged_path": [4, 8], "shuffle_buff": [4, 8], "size_valid_set": [4, 8], "split": [4, 8], "stream": [4, 8], "target_kl": [4, 8], "top_k": [4, 8], "top_p": [4, 8], "total_ppo_epoch": [4, 8], "train_test_split_ratio": [4, 8], "weight_decai": [4, 8], "rewarddatacollatorwithpad": [4, 8], "rewardtrain": [4, 8], "compute_loss": [4, 8], "create_dataset": [4, 8], "save": [4, 6, 8], "train_and_sav": [4, 8], "sft": [4, 8], "rlhf_config": [4, 8], "token": [4, 7, 8], "num_proc": [4, 8], "dataset": [4, 8], "torch_dtyp": [4, 8], "training_arg": [4, 8], "trainer": [4, 8], "load_lora": [4, 8], "prepare_sample_text": [4, 8], "train": [4, 8], "read_json_fil": [4, 8], "class": [4, 5, 6, 7, 8], "share": 4, "bool": [4, 6, 7, 8], "fals": [4, 6, 8], "debug": [4, 6], "sourc": [4, 5, 6, 7, 8], "object": [4, 5, 6, 7, 8], "The": [4, 5, 6, 7, 8], "ani": [4, 5, 7], "add": 4, "paramet": [4, 5, 6, 7, 8], "ad": 4, "app": 4, "flask": 4, "dict": [4, 5, 8], "str": [4, 5, 6, 7, 8], "rout": 4, "which": [4, 6, 7], "ar": [4, 8], "being": 4, "feedback": [4, 5, 8], "4": [4, 8], "jare": 4, "kwarg": [5, 7], "repres": [5, 6, 7, 8], "us": [5, 6, 7, 8], "type": [5, 6, 7, 8], "callabl": 5, "i": [0, 1, 2, 5, 6, 7, 8, 9], "all": [5, 6, 7, 8], "uniqu": 5, "identifi": 5, "data": [0, 1, 2, 5, 6, 8, 9], "svelt": 5, "addit": 5, "properti": 5, "fetch": 5, "from": [0, 1, 2, 5, 6, 7, 8, 9], "provid": [5, 7, 8], "function": 5, "list": [5, 6, 7, 8], "column": [5, 6], "valu": [5, 6, 7], "factori": [5, 7, 8], "A": [5, 6, 7, 8], "static": [5, 7], "union": [5, 7], "return": [5, 6, 7, 8], "enum": [5, 7], "question": [6, 8], "answer": [6, 8], "db_file": 6, "user": 6, "jaredwilb": 6, "desktop": 6, "doc": 6, "qd": [6, 8], "close": 6, "connect": 6, "question_answ": 6, "tabl": 6, "doe": 6, "alreadi": 6, "exist": 6, "ha": 6, "four": 6, "primari": 6, "kei": 6, "vote_statu": 6, "text": [6, 7, 8], "field": 6, "can": 6, "onli": 6, "have": 6, "up": 6, "down": 6, "n": 6, "thread": 6, "local": 6, "cursor": 6, "insert": 6, "new": 6, "pair": 6, "given": [6, 7], "set": 6, "default": [6, 7, 8], "newli": 6, "row": 6, "int": [6, 7, 8], "print": 6, "format": 6, "manner": 6, "tupl": 6, "where": 6, "each": [6, 7], "contain": [6, 8], "five": 6, "element": [6, 8], "timestamp": 6, "statu": 6, "retriev": 6, "panda": 6, "datafram": 6, "csv_file_nam": 6, "question_answer_vot": 6, "csv": 6, "thi": [0, 1, 2, 6, 7, 8, 9], "method": [6, 7], "file": [6, 8], "option": [6, 7, 8], "written": 6, "follow": 6, "correspond": [6, 7], "first": [6, 8], "call": 6, "It": [0, 1, 2, 6, 7, 9], "write": 6, "updat": 6, "must": [6, 7], "one": 6, "rais": [6, 7], "valueerror": [6, 7], "If": [6, 7, 8], "up_ranking_answ": 6, "low_ranking_answ": 6, "entri": 6, "higher": 6, "lower": 6, "ranking_data": 6, "abstract": 7, "abc": 7, "an": 7, "ensur": 7, "subclass": [7, 8], "implement": 7, "messag": 7, "num_of_respons": 7, "next": 7, "word": 7, "input": [7, 8], "how": [7, 8], "mani": 7, "complet": 7, "gener": 7, "prompt": 7, "notimplementederror": 7, "enumer": 7, "avail": 7, "peft": [7, 8], "languag": 7, "pretrained_model_name_or_path": 7, "trust_remote_cod": 7, "true": [7, 8], "max_length": [7, 8], "100": [7, 8], "auto": 7, "wrapper": 7, "chain": 7, "inherit": 7, "1": [7, 8], "number": [7, 8], "respons": 7, "defin": 7, "instanc": 7, "model_sourc": 7, "tri": 7, "match": 7, "found": 7, "valid": 7, "api_kei": 7, "engin": 7, "davinci": 7, "max_token": 7, "temperatur": 7, "float": [7, 8], "0": [7, 8], "5": [7, 8], "wrap": 7, "llmchain": 7, "maximum": 7, "__init__": 7, "self": 7, "initi": 7, "lora_model_path": [7, 8], "peftmodel": 7, "autotoken": [7, 8], "length": 7, "meta": 8, "llama": 8, "2": 8, "7b": 8, "hf": 8, "local_db": 8, "5000": 8, "512": 8, "step": 8, "8": 8, "100000": 8, "1e": 8, "05": 8, "01": 8, "rlhf_checkpoint": 8, "1000": 8, "finetun": 8, "10000": 8, "4000": 8, "step1_supervised_finetuning_lora_fin": 8, "step1_supervised_finetuning_merg": 8, "cosin": 8, "tuner": 8, "lora": 8, "loraconfig": 8, "peft_typ": 8, "pefttyp": 8, "auto_map": 8, "base_model_name_or_path": 8, "revis": 8, "task_typ": 8, "tasktyp": 8, "causal_lm": 8, "inference_mod": 8, "r": 8, "32": 8, "target_modul": 8, "lora_alpha": 8, "64": 8, "lora_dropout": 8, "fan_in_fan_out": 8, "bia": 8, "modules_to_sav": 8, "init_lora_weight": 8, "layers_to_transform": 8, "layers_pattern": 8, "databrick": 8, "dolli": 8, "v2": 8, "3b": 8, "reward": 8, "evalu": 8, "10": 8, "seq_cl": 8, "16": 8, "128": 8, "20000": 8, "configur": 8, "reinforc": 8, "learn": 8, "human": 8, "divid": 8, "three": 8, "supervis": 8, "fine": 8, "tune": 8, "3": 8, "return_output": 8, "loss": 8, "comput": 8, "By": 8, "overrid": 8, "custom": 8, "behavior": 8, "load": 8, "preprocess": 8, "dictionari": 8, "eval": 8, "output_path": 8, "output": 8, "path": 8, "worker": 8, "torch": 8, "dtype": 8, "argument": 8, "trainingargu": 8, "automodelforcausallm": 8, "sfttrainer": 8, "arg": 8, "exampl": 8, "prepar": 8, "sampl": 8, "file_path": 8, "read": 8, "json": 8, "its": 8, "cambioml": 1, "lu": [0, 1, 2, 9], "make": [0, 1, 2, 9], "python": [0, 1, 2, 9], "librari": [0, 1, 2, 9], "cook": [0, 1, 2, 9], "food": [0, 1, 2, 9], "lover": [0, 1, 2, 9], "recip": [0, 1, 2, 9], "mix": [0, 1, 2, 9], "random": [0, 1, 2, 9], "ingredi": [0, 1, 2, 9], "pull": [0, 1, 2, 9], "open": [0, 1, 2, 9], "fact": [0, 1, 2, 9], "offer": [0, 1, 2, 9], "simpl": [0, 1, 2, 9], "intuit": [0, 1, 2, 9], "api": [0, 1, 2, 9], "project": [0, 1, 2, 9], "under": [0, 1, 2, 9], "activ": [0, 1, 2, 9], "develop": [0, 1, 2, 9], "lumach": [0, 2, 9], "get": 1, "start": 1, "quick": 1, "tour": 1}, "objects": {"": [[4, 0, 0, "-", "pykoi"]], "pykoi": [[4, 0, 0, "-", "application"], [5, 0, 0, "-", "component"], [6, 0, 0, "-", "db"], [7, 0, 0, "-", "llm"], [8, 0, 0, "-", "rlhf"], [4, 0, 0, "-", "state"]], "pykoi.application": [[4, 1, 1, "", "Application"], [4, 3, 1, "", "find_free_port"]], "pykoi.application.Application": [[4, 2, 1, "", "add_component"], [4, 2, 1, "", "create_chatbot_route"], [4, 2, 1, "", "create_feedback_route"], [4, 2, 1, "", "run"]], "pykoi.component": [[5, 0, 0, "-", "base"], [5, 0, 0, "-", "chatbot_database_factory"], [5, 0, 0, "-", "constants"]], "pykoi.component.base": [[5, 1, 1, "", "Chatbot"], [5, 1, 1, "", "Component"], [5, 1, 1, "", "Dashboard"], [5, 1, 1, "", "DataSource"], [5, 1, 1, "", "Dropdown"]], "pykoi.component.base.Chatbot": [[5, 4, 1, "", "database"], [5, 4, 1, "", "model"]], "pykoi.component.base.Component": [[5, 4, 1, "", "data_source"], [5, 4, 1, "", "id"], [5, 4, 1, "", "props"], [5, 4, 1, "", "svelte_component"]], "pykoi.component.base.Dashboard": [[5, 4, 1, "", "database"]], "pykoi.component.base.DataSource": [[5, 4, 1, "", "fetch_func"], [5, 4, 1, "", "id"]], "pykoi.component.base.Dropdown": [[5, 4, 1, "", "value_column"]], "pykoi.component.chatbot_database_factory": [[5, 1, 1, "", "ChatbotDatabaseFactory"]], "pykoi.component.chatbot_database_factory.ChatbotDatabaseFactory": [[5, 2, 1, "", "create"]], "pykoi.component.constants": [[5, 1, 1, "", "FeedbackType"]], "pykoi.component.constants.FeedbackType": [[5, 4, 1, "", "RANK"], [5, 4, 1, "", "VOTE"]], "pykoi.db": [[6, 0, 0, "-", "qa_database"], [6, 0, 0, "-", "ranking_database"]], "pykoi.db.qa_database": [[6, 1, 1, "", "QuestionAnswerDatabase"]], "pykoi.db.qa_database.QuestionAnswerDatabase": [[6, 2, 1, "", "close_connection"], [6, 2, 1, "", "create_table"], [6, 2, 1, "", "get_connection"], [6, 2, 1, "", "get_cursor"], [6, 2, 1, "", "insert_question_answer"], [6, 2, 1, "", "print_table"], [6, 2, 1, "", "retrieve_all_question_answers"], [6, 2, 1, "", "retrieve_all_question_answers_as_pandas"], [6, 2, 1, "", "save_to_csv"], [6, 2, 1, "", "update_vote_status"]], "pykoi.db.ranking_database": [[6, 1, 1, "", "RankingDatabase"]], "pykoi.db.ranking_database.RankingDatabase": [[6, 2, 1, "", "close_connection"], [6, 2, 1, "", "create_table"], [6, 2, 1, "", "get_connection"], [6, 2, 1, "", "get_cursor"], [6, 2, 1, "", "insert_ranking"], [6, 2, 1, "", "print_table"], [6, 2, 1, "", "retrieve_all_question_answers"], [6, 2, 1, "", "save_to_csv"]], "pykoi.llm": [[7, 0, 0, "-", "abs_llm"], [7, 0, 0, "-", "constants"], [7, 0, 0, "-", "huggingface"], [7, 0, 0, "-", "model_factory"], [7, 0, 0, "-", "openai"], [7, 0, 0, "-", "peft_huggingface"]], "pykoi.llm.abs_llm": [[7, 1, 1, "", "AbsLlm"]], "pykoi.llm.abs_llm.AbsLlm": [[7, 4, 1, "", "None"], [7, 2, 1, "", "predict"]], "pykoi.llm.constants": [[7, 1, 1, "", "ModelSource"]], "pykoi.llm.constants.ModelSource": [[7, 4, 1, "id0", "HUGGINGFACE"], [7, 4, 1, "id1", "OPENAI"], [7, 4, 1, "id2", "PEFT_HUGGINGFACE"]], "pykoi.llm.huggingface": [[7, 1, 1, "", "HuggingfaceModel"]], "pykoi.llm.huggingface.HuggingfaceModel": [[7, 2, 1, "", "predict"]], "pykoi.llm.model_factory": [[7, 1, 1, "", "ModelFactory"]], "pykoi.llm.model_factory.ModelFactory": [[7, 2, 1, "", "create_model"]], "pykoi.llm.openai": [[7, 1, 1, "", "OpenAIModel"]], "pykoi.llm.openai.OpenAIModel": [[7, 4, 1, "", "_engine"], [7, 4, 1, "", "_max_tokens"], [7, 4, 1, "", "_temperature"], [7, 2, 1, "", "predict"]], "pykoi.llm.peft_huggingface": [[7, 1, 1, "", "PeftHuggingfacemodel"]], "pykoi.llm.peft_huggingface.PeftHuggingfacemodel": [[7, 4, 1, "", "_max_length"], [7, 4, 1, "", "_model"], [7, 4, 1, "", "_tokenizer"], [7, 2, 1, "", "predict"]], "pykoi.rlhf": [[8, 0, 0, "-", "rlhf"]], "pykoi.rlhf.rlhf": [[8, 1, 1, "", "RLHFConfig"], [8, 1, 1, "", "RewardDataCollatorWithPadding"], [8, 1, 1, "", "RewardTrainer"], [8, 1, 1, "", "SFT"], [8, 3, 1, "", "read_json_file"]], "pykoi.rlhf.rlhf.RLHFConfig": [[8, 4, 1, "", "adafactor"], [8, 4, 1, "", "adap_kl_ctrl"], [8, 4, 1, "", "answer_title"], [8, 4, 1, "", "base_model_path"], [8, 4, 1, "", "bf16"], [8, 4, 1, "", "dataset_eval_folder"], [8, 4, 1, "", "dataset_name"], [8, 4, 1, "", "dataset_reward_folder"], [8, 4, 1, "", "dataset_subset_rl"], [8, 4, 1, "", "dataset_subset_rl_train"], [8, 4, 1, "", "dataset_subset_sft"], [8, 4, 1, "", "dataset_subset_sft_train"], [8, 4, 1, "", "dataset_type"], [8, 4, 1, "", "deepspeed"], [8, 4, 1, "", "device_map"], [8, 4, 1, "", "do_sample"], [8, 4, 1, "", "early_stopping"], [8, 4, 1, "", "eos_token_id"], [8, 4, 1, "", "eval_freq"], [8, 4, 1, "", "evaluation_strategy"], [8, 4, 1, "", "fp16"], [8, 4, 1, "", "gradient_accumulation_steps"], [8, 4, 1, "", "gradient_checkpointing"], [8, 4, 1, "", "init_kl_coef"], [8, 4, 1, "", "label_names"], [8, 4, 1, "", "learning_rate"], [8, 4, 1, "", "load_in_8bit"], [8, 4, 1, "", "local_rank"], [8, 4, 1, "", "log_freq"], [8, 4, 1, "", "logging_steps"], [8, 4, 1, "", "logging_strategy"], [8, 4, 1, "", "lora_config_reward"], [8, 4, 1, "", "lora_config_rl"], [8, 4, 1, "", "lr_scheduler_type_sft"], [8, 4, 1, "", "max_seq_length"], [8, 4, 1, "", "max_seq_length_reward"], [8, 4, 1, "", "max_steps"], [8, 4, 1, "", "mini_batch_size"], [8, 4, 1, "", "num_warmup_steps"], [8, 4, 1, "", "num_workers"], [8, 4, 1, "", "output_dir"], [8, 4, 1, "", "output_max_length"], [8, 4, 1, "", "per_device_eval_batch_size"], [8, 4, 1, "", "per_device_train_batch_size"], [8, 4, 1, "", "ppo_batch_size"], [8, 4, 1, "", "ppo_epochs"], [8, 4, 1, "", "push_to_hub"], [8, 4, 1, "", "question_title"], [8, 4, 1, "", "remove_unused_columns"], [8, 4, 1, "", "resume_from_checkpoint"], [8, 4, 1, "", "reward_baseline"], [8, 4, 1, "", "reward_epochs"], [8, 4, 1, "", "reward_lora_path"], [8, 4, 1, "", "reward_merged_path"], [8, 4, 1, "", "reward_model_path"], [8, 4, 1, "", "reward_num_of_data"], [8, 4, 1, "", "save_freq"], [8, 4, 1, "", "seed"], [8, 4, 1, "", "sft_lora_path"], [8, 4, 1, "", "sft_merged_path"], [8, 4, 1, "", "shuffle_buffer"], [8, 4, 1, "", "size_valid_set"], [8, 4, 1, "", "split"], [8, 4, 1, "", "streaming"], [8, 4, 1, "", "target_kl"], [8, 4, 1, "", "top_k"], [8, 4, 1, "", "top_p"], [8, 4, 1, "", "total_ppo_epochs"], [8, 4, 1, "", "train_test_split_ratio"], [8, 4, 1, "", "weight_decay"]], "pykoi.rlhf.rlhf.RewardTrainer": [[8, 2, 1, "", "compute_loss"], [8, 2, 1, "", "create_datasets"], [8, 2, 1, "", "save"], [8, 2, 1, "", "train_and_save"]], "pykoi.rlhf.rlhf.SFT": [[8, 2, 1, "", "create_datasets"], [8, 4, 1, "", "dataset"], [8, 2, 1, "", "load_lora"], [8, 4, 1, "", "model"], [8, 4, 1, "", "num_proc"], [8, 2, 1, "", "prepare_sample_text"], [8, 4, 1, "", "rlhf_config"], [8, 2, 1, "", "save"], [8, 4, 1, "", "tokenizer"], [8, 4, 1, "", "torch_dtype"], [8, 2, 1, "", "train"], [8, 2, 1, "", "train_and_save"], [8, 4, 1, "", "trainer"], [8, 4, 1, "", "training_args"]], "pykoi.state": [[4, 1, 1, "", "State"], [4, 1, 1, "", "Store"]], "pykoi.state.Store": [[4, 4, 1, "", "count"], [4, 2, 1, "", "decrement"], [4, 2, 1, "", "hello"], [4, 2, 1, "", "increment"], [4, 4, 1, "", "name"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function", "4": "py:attribute"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"], "4": ["py", "attribute", "Python attribute"]}, "titleterms": {"welcom": 1, "pykoi": [1, 3, 4, 5, 6, 7, 8], "": 1, "document": 1, "content": [1, 4, 5, 6, 7, 8], "indic": 1, "tabl": 1, "packag": [4, 5, 6, 7, 8], "subpackag": 4, "submodul": [4, 5, 6, 7, 8], "applic": 4, "modul": [4, 5, 6, 7, 8], "state": 4, "compon": 5, "base": 5, "chatbot_database_factori": 5, "constant": [5, 7], "db": 6, "qa_databas": 6, "ranking_databas": 6, "llm": 7, "abs_llm": 7, "huggingfac": 7, "model_factori": 7, "openai": 7, "peft_huggingfac": 7, "rlhf": 8, "lumach": 1, "get": [2, 9], "start": [2, 9], "quick": 0, "tour": 0}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Quick Tour": [[0, "quick-tour"]], "Welcome to pykoi\u2019s documentation!": [[1, "welcome-to-pykoi-s-documentation"]], "Contents:": [[1, null]], "Indices and tables": [[1, "indices-and-tables"]], "Welcome to Lumache\u2019s documentation!": [[1, "welcome-to-lumache-s-documentation"]], "Getting Started": [[2, "getting-started"], [9, "getting-started"]], "pykoi": [[3, "pykoi"]], "pykoi package": [[4, "pykoi-package"]], "Subpackages": [[4, "subpackages"]], "Submodules": [[4, "submodules"], [5, "submodules"], [6, "submodules"], [7, "submodules"], [8, "submodules"]], "pykoi.application module": [[4, "module-pykoi.application"]], "pykoi.state module": [[4, "module-pykoi.state"]], "Module contents": [[4, "module-pykoi"], [5, "module-pykoi.component"], [6, "module-pykoi.db"], [7, "module-pykoi.llm"], [8, "module-pykoi.rlhf"]], "pykoi.component package": [[5, "pykoi-component-package"]], "pykoi.component.base module": [[5, "module-pykoi.component.base"]], "pykoi.component.chatbot_database_factory module": [[5, "module-pykoi.component.chatbot_database_factory"]], "pykoi.component.constants module": [[5, "module-pykoi.component.constants"]], "pykoi.db package": [[6, "pykoi-db-package"]], "pykoi.db.qa_database module": [[6, "module-pykoi.db.qa_database"]], "pykoi.db.ranking_database module": [[6, "module-pykoi.db.ranking_database"]], "pykoi.llm package": [[7, "pykoi-llm-package"]], "pykoi.llm.abs_llm module": [[7, "module-pykoi.llm.abs_llm"]], "pykoi.llm.constants module": [[7, "module-pykoi.llm.constants"]], "pykoi.llm.huggingface module": [[7, "module-pykoi.llm.huggingface"]], "pykoi.llm.model_factory module": [[7, "module-pykoi.llm.model_factory"]], "pykoi.llm.openai module": [[7, "module-pykoi.llm.openai"]], "pykoi.llm.peft_huggingface module": [[7, "module-pykoi.llm.peft_huggingface"]], "pykoi.rlhf package": [[8, "pykoi-rlhf-package"]], "pykoi.rlhf.rlhf module": [[8, "module-pykoi.rlhf.rlhf"]]}, "indexentries": {"application (class in pykoi.application)": [[4, "pykoi.application.Application"]], "state (class in pykoi.state)": [[4, "pykoi.state.State"]], "store (class in pykoi.state)": [[4, "pykoi.state.Store"]], "add_component() (pykoi.application.application method)": [[4, "pykoi.application.Application.add_component"]], "count (pykoi.state.store attribute)": [[4, "pykoi.state.Store.count"]], "create_chatbot_route() (pykoi.application.application method)": [[4, "pykoi.application.Application.create_chatbot_route"]], "create_feedback_route() (pykoi.application.application method)": [[4, "pykoi.application.Application.create_feedback_route"]], "decrement() (pykoi.state.store method)": [[4, "pykoi.state.Store.decrement"]], "find_free_port() (in module pykoi.application)": [[4, "pykoi.application.find_free_port"]], "hello() (pykoi.state.store method)": [[4, "pykoi.state.Store.hello"]], "increment() (pykoi.state.store method)": [[4, "pykoi.state.Store.increment"]], "module": [[4, "module-pykoi"], [4, "module-pykoi.application"], [4, "module-pykoi.state"], [5, "module-pykoi.component"], [5, "module-pykoi.component.base"], [5, "module-pykoi.component.chatbot_database_factory"], [5, "module-pykoi.component.constants"], [6, "module-pykoi.db"], [6, "module-pykoi.db.qa_database"], [6, "module-pykoi.db.ranking_database"], [7, "module-pykoi.llm"], [7, "module-pykoi.llm.abs_llm"], [7, "module-pykoi.llm.constants"], [7, "module-pykoi.llm.huggingface"], [7, "module-pykoi.llm.model_factory"], [7, "module-pykoi.llm.openai"], [7, "module-pykoi.llm.peft_huggingface"], [8, "module-pykoi.rlhf"], [8, "module-pykoi.rlhf.rlhf"]], "name (pykoi.state.store attribute)": [[4, "pykoi.state.Store.name"]], "pykoi": [[4, "module-pykoi"]], "pykoi.application": [[4, "module-pykoi.application"]], "pykoi.state": [[4, "module-pykoi.state"]], "run() (pykoi.application.application method)": [[4, "pykoi.application.Application.run"]], "chatbot (class in pykoi.component.base)": [[5, "pykoi.component.base.Chatbot"]], "chatbotdatabasefactory (class in pykoi.component.chatbot_database_factory)": [[5, "pykoi.component.chatbot_database_factory.ChatbotDatabaseFactory"]], "component (class in pykoi.component.base)": [[5, "pykoi.component.base.Component"]], "dashboard (class in pykoi.component.base)": [[5, "pykoi.component.base.Dashboard"]], "datasource (class in pykoi.component.base)": [[5, "pykoi.component.base.DataSource"]], "dropdown (class in pykoi.component.base)": [[5, "pykoi.component.base.Dropdown"]], "feedbacktype (class in pykoi.component.constants)": [[5, "pykoi.component.constants.FeedbackType"]], "rank (pykoi.component.constants.feedbacktype attribute)": [[5, "pykoi.component.constants.FeedbackType.RANK"]], "vote (pykoi.component.constants.feedbacktype attribute)": [[5, "pykoi.component.constants.FeedbackType.VOTE"]], "create() (pykoi.component.chatbot_database_factory.chatbotdatabasefactory static method)": [[5, "pykoi.component.chatbot_database_factory.ChatbotDatabaseFactory.create"]], "data_source (pykoi.component.base.component attribute)": [[5, "pykoi.component.base.Component.data_source"]], "database (pykoi.component.base.chatbot attribute)": [[5, "pykoi.component.base.Chatbot.database"]], "database (pykoi.component.base.dashboard attribute)": [[5, "pykoi.component.base.Dashboard.database"]], "fetch_func (pykoi.component.base.datasource attribute)": [[5, "pykoi.component.base.DataSource.fetch_func"]], "id (pykoi.component.base.component attribute)": [[5, "pykoi.component.base.Component.id"]], "id (pykoi.component.base.datasource attribute)": [[5, "pykoi.component.base.DataSource.id"]], "model (pykoi.component.base.chatbot attribute)": [[5, "pykoi.component.base.Chatbot.model"]], "props (pykoi.component.base.component attribute)": [[5, "pykoi.component.base.Component.props"]], "pykoi.component": [[5, "module-pykoi.component"]], "pykoi.component.base": [[5, "module-pykoi.component.base"]], "pykoi.component.chatbot_database_factory": [[5, "module-pykoi.component.chatbot_database_factory"]], "pykoi.component.constants": [[5, "module-pykoi.component.constants"]], "svelte_component (pykoi.component.base.component attribute)": [[5, "pykoi.component.base.Component.svelte_component"]], "value_column (pykoi.component.base.dropdown attribute)": [[5, "pykoi.component.base.Dropdown.value_column"]], "questionanswerdatabase (class in pykoi.db.qa_database)": [[6, "pykoi.db.qa_database.QuestionAnswerDatabase"]], "rankingdatabase (class in pykoi.db.ranking_database)": [[6, "pykoi.db.ranking_database.RankingDatabase"]], "close_connection() (pykoi.db.qa_database.questionanswerdatabase method)": [[6, "pykoi.db.qa_database.QuestionAnswerDatabase.close_connection"]], "close_connection() (pykoi.db.ranking_database.rankingdatabase method)": [[6, "pykoi.db.ranking_database.RankingDatabase.close_connection"]], "create_table() (pykoi.db.qa_database.questionanswerdatabase method)": [[6, "pykoi.db.qa_database.QuestionAnswerDatabase.create_table"]], "create_table() (pykoi.db.ranking_database.rankingdatabase method)": [[6, "pykoi.db.ranking_database.RankingDatabase.create_table"]], "get_connection() (pykoi.db.qa_database.questionanswerdatabase method)": [[6, "pykoi.db.qa_database.QuestionAnswerDatabase.get_connection"]], "get_connection() (pykoi.db.ranking_database.rankingdatabase method)": [[6, "pykoi.db.ranking_database.RankingDatabase.get_connection"]], "get_cursor() (pykoi.db.qa_database.questionanswerdatabase method)": [[6, "pykoi.db.qa_database.QuestionAnswerDatabase.get_cursor"]], "get_cursor() (pykoi.db.ranking_database.rankingdatabase method)": [[6, "pykoi.db.ranking_database.RankingDatabase.get_cursor"]], "insert_question_answer() (pykoi.db.qa_database.questionanswerdatabase method)": [[6, "pykoi.db.qa_database.QuestionAnswerDatabase.insert_question_answer"]], "insert_ranking() (pykoi.db.ranking_database.rankingdatabase method)": [[6, "pykoi.db.ranking_database.RankingDatabase.insert_ranking"]], "print_table() (pykoi.db.qa_database.questionanswerdatabase method)": [[6, "pykoi.db.qa_database.QuestionAnswerDatabase.print_table"]], "print_table() (pykoi.db.ranking_database.rankingdatabase method)": [[6, "pykoi.db.ranking_database.RankingDatabase.print_table"]], "pykoi.db": [[6, "module-pykoi.db"]], "pykoi.db.qa_database": [[6, "module-pykoi.db.qa_database"]], "pykoi.db.ranking_database": [[6, "module-pykoi.db.ranking_database"]], "retrieve_all_question_answers() (pykoi.db.qa_database.questionanswerdatabase method)": [[6, "pykoi.db.qa_database.QuestionAnswerDatabase.retrieve_all_question_answers"]], "retrieve_all_question_answers() (pykoi.db.ranking_database.rankingdatabase method)": [[6, "pykoi.db.ranking_database.RankingDatabase.retrieve_all_question_answers"]], "retrieve_all_question_answers_as_pandas() (pykoi.db.qa_database.questionanswerdatabase method)": [[6, "pykoi.db.qa_database.QuestionAnswerDatabase.retrieve_all_question_answers_as_pandas"]], "save_to_csv() (pykoi.db.qa_database.questionanswerdatabase method)": [[6, "pykoi.db.qa_database.QuestionAnswerDatabase.save_to_csv"]], "save_to_csv() (pykoi.db.ranking_database.rankingdatabase method)": [[6, "pykoi.db.ranking_database.RankingDatabase.save_to_csv"]], "update_vote_status() (pykoi.db.qa_database.questionanswerdatabase method)": [[6, "pykoi.db.qa_database.QuestionAnswerDatabase.update_vote_status"]], "absllm (class in pykoi.llm.abs_llm)": [[7, "pykoi.llm.abs_llm.AbsLlm"]], "huggingface (pykoi.llm.constants.modelsource attribute)": [[7, "id0"], [7, "pykoi.llm.constants.ModelSource.HUGGINGFACE"]], "huggingfacemodel (class in pykoi.llm.huggingface)": [[7, "pykoi.llm.huggingface.HuggingfaceModel"]], "modelfactory (class in pykoi.llm.model_factory)": [[7, "pykoi.llm.model_factory.ModelFactory"]], "modelsource (class in pykoi.llm.constants)": [[7, "pykoi.llm.constants.ModelSource"]], "none (pykoi.llm.abs_llm.absllm attribute)": [[7, "pykoi.llm.abs_llm.AbsLlm.None"]], "openai (pykoi.llm.constants.modelsource attribute)": [[7, "id1"], [7, "pykoi.llm.constants.ModelSource.OPENAI"]], "openaimodel (class in pykoi.llm.openai)": [[7, "pykoi.llm.openai.OpenAIModel"]], "peft_huggingface (pykoi.llm.constants.modelsource attribute)": [[7, "id2"], [7, "pykoi.llm.constants.ModelSource.PEFT_HUGGINGFACE"]], "pefthuggingfacemodel (class in pykoi.llm.peft_huggingface)": [[7, "pykoi.llm.peft_huggingface.PeftHuggingfacemodel"]], "_engine (pykoi.llm.openai.openaimodel attribute)": [[7, "pykoi.llm.openai.OpenAIModel._engine"]], "_max_length (pykoi.llm.peft_huggingface.pefthuggingfacemodel attribute)": [[7, "pykoi.llm.peft_huggingface.PeftHuggingfacemodel._max_length"]], "_max_tokens (pykoi.llm.openai.openaimodel attribute)": [[7, "pykoi.llm.openai.OpenAIModel._max_tokens"]], "_model (pykoi.llm.peft_huggingface.pefthuggingfacemodel attribute)": [[7, "pykoi.llm.peft_huggingface.PeftHuggingfacemodel._model"]], "_temperature (pykoi.llm.openai.openaimodel attribute)": [[7, "pykoi.llm.openai.OpenAIModel._temperature"]], "_tokenizer (pykoi.llm.peft_huggingface.pefthuggingfacemodel attribute)": [[7, "pykoi.llm.peft_huggingface.PeftHuggingfacemodel._tokenizer"]], "create_model() (pykoi.llm.model_factory.modelfactory static method)": [[7, "pykoi.llm.model_factory.ModelFactory.create_model"]], "predict() (pykoi.llm.abs_llm.absllm method)": [[7, "pykoi.llm.abs_llm.AbsLlm.predict"]], "predict() (pykoi.llm.huggingface.huggingfacemodel method)": [[7, "pykoi.llm.huggingface.HuggingfaceModel.predict"]], "predict() (pykoi.llm.openai.openaimodel method)": [[7, "pykoi.llm.openai.OpenAIModel.predict"]], "predict() (pykoi.llm.peft_huggingface.pefthuggingfacemodel method)": [[7, "pykoi.llm.peft_huggingface.PeftHuggingfacemodel.predict"]], "pykoi.llm": [[7, "module-pykoi.llm"]], "pykoi.llm.abs_llm": [[7, "module-pykoi.llm.abs_llm"]], "pykoi.llm.constants": [[7, "module-pykoi.llm.constants"]], "pykoi.llm.huggingface": [[7, "module-pykoi.llm.huggingface"]], "pykoi.llm.model_factory": [[7, "module-pykoi.llm.model_factory"]], "pykoi.llm.openai": [[7, "module-pykoi.llm.openai"]], "pykoi.llm.peft_huggingface": [[7, "module-pykoi.llm.peft_huggingface"]], "rlhfconfig (class in pykoi.rlhf.rlhf)": [[8, "pykoi.rlhf.rlhf.RLHFConfig"]], "rewarddatacollatorwithpadding (class in pykoi.rlhf.rlhf)": [[8, "pykoi.rlhf.rlhf.RewardDataCollatorWithPadding"]], "rewardtrainer (class in pykoi.rlhf.rlhf)": [[8, "pykoi.rlhf.rlhf.RewardTrainer"]], "sft (class in pykoi.rlhf.rlhf)": [[8, "pykoi.rlhf.rlhf.SFT"]], "adafactor (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.adafactor"]], "adap_kl_ctrl (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.adap_kl_ctrl"]], "answer_title (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.answer_title"]], "base_model_path (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.base_model_path"]], "bf16 (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.bf16"]], "compute_loss() (pykoi.rlhf.rlhf.rewardtrainer method)": [[8, "pykoi.rlhf.rlhf.RewardTrainer.compute_loss"]], "create_datasets() (pykoi.rlhf.rlhf.rewardtrainer method)": [[8, "pykoi.rlhf.rlhf.RewardTrainer.create_datasets"]], "create_datasets() (pykoi.rlhf.rlhf.sft method)": [[8, "pykoi.rlhf.rlhf.SFT.create_datasets"]], "dataset (pykoi.rlhf.rlhf.sft attribute)": [[8, "pykoi.rlhf.rlhf.SFT.dataset"]], "dataset_eval_folder (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.dataset_eval_folder"]], "dataset_name (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.dataset_name"]], "dataset_reward_folder (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.dataset_reward_folder"]], "dataset_subset_rl (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.dataset_subset_rl"]], "dataset_subset_rl_train (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.dataset_subset_rl_train"]], "dataset_subset_sft (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.dataset_subset_sft"]], "dataset_subset_sft_train (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.dataset_subset_sft_train"]], "dataset_type (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.dataset_type"]], "deepspeed (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.deepspeed"]], "device_map (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.device_map"]], "do_sample (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.do_sample"]], "early_stopping (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.early_stopping"]], "eos_token_id (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.eos_token_id"]], "eval_freq (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.eval_freq"]], "evaluation_strategy (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.evaluation_strategy"]], "fp16 (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.fp16"]], "gradient_accumulation_steps (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.gradient_accumulation_steps"]], "gradient_checkpointing (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.gradient_checkpointing"]], "init_kl_coef (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.init_kl_coef"]], "label_names (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.label_names"]], "learning_rate (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.learning_rate"]], "load_in_8bit (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.load_in_8bit"]], "load_lora() (pykoi.rlhf.rlhf.sft method)": [[8, "pykoi.rlhf.rlhf.SFT.load_lora"]], "local_rank (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.local_rank"]], "log_freq (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.log_freq"]], "logging_steps (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.logging_steps"]], "logging_strategy (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.logging_strategy"]], "lora_config_reward (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.lora_config_reward"]], "lora_config_rl (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.lora_config_rl"]], "lr_scheduler_type_sft (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.lr_scheduler_type_sft"]], "max_seq_length (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.max_seq_length"]], "max_seq_length_reward (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.max_seq_length_reward"]], "max_steps (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.max_steps"]], "mini_batch_size (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.mini_batch_size"]], "model (pykoi.rlhf.rlhf.sft attribute)": [[8, "pykoi.rlhf.rlhf.SFT.model"]], "num_proc (pykoi.rlhf.rlhf.sft attribute)": [[8, "pykoi.rlhf.rlhf.SFT.num_proc"]], "num_warmup_steps (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.num_warmup_steps"]], "num_workers (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.num_workers"]], "output_dir (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.output_dir"]], "output_max_length (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.output_max_length"]], "per_device_eval_batch_size (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.per_device_eval_batch_size"]], "per_device_train_batch_size (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.per_device_train_batch_size"]], "ppo_batch_size (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.ppo_batch_size"]], "ppo_epochs (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.ppo_epochs"]], "prepare_sample_text() (pykoi.rlhf.rlhf.sft method)": [[8, "pykoi.rlhf.rlhf.SFT.prepare_sample_text"]], "push_to_hub (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.push_to_hub"]], "pykoi.rlhf": [[8, "module-pykoi.rlhf"]], "pykoi.rlhf.rlhf": [[8, "module-pykoi.rlhf.rlhf"]], "question_title (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.question_title"]], "read_json_file() (in module pykoi.rlhf.rlhf)": [[8, "pykoi.rlhf.rlhf.read_json_file"]], "remove_unused_columns (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.remove_unused_columns"]], "resume_from_checkpoint (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.resume_from_checkpoint"]], "reward_baseline (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.reward_baseline"]], "reward_epochs (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.reward_epochs"]], "reward_lora_path (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.reward_lora_path"]], "reward_merged_path (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.reward_merged_path"]], "reward_model_path (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.reward_model_path"]], "reward_num_of_data (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.reward_num_of_data"]], "rlhf_config (pykoi.rlhf.rlhf.sft attribute)": [[8, "pykoi.rlhf.rlhf.SFT.rlhf_config"]], "save() (pykoi.rlhf.rlhf.rewardtrainer method)": [[8, "pykoi.rlhf.rlhf.RewardTrainer.save"]], "save() (pykoi.rlhf.rlhf.sft method)": [[8, "pykoi.rlhf.rlhf.SFT.save"]], "save_freq (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.save_freq"]], "seed (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.seed"]], "sft_lora_path (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.sft_lora_path"]], "sft_merged_path (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.sft_merged_path"]], "shuffle_buffer (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.shuffle_buffer"]], "size_valid_set (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.size_valid_set"]], "split (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.split"]], "streaming (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.streaming"]], "target_kl (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.target_kl"]], "tokenizer (pykoi.rlhf.rlhf.sft attribute)": [[8, "pykoi.rlhf.rlhf.SFT.tokenizer"]], "top_k (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.top_k"]], "top_p (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.top_p"]], "torch_dtype (pykoi.rlhf.rlhf.sft attribute)": [[8, "pykoi.rlhf.rlhf.SFT.torch_dtype"]], "total_ppo_epochs (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.total_ppo_epochs"]], "train() (pykoi.rlhf.rlhf.sft method)": [[8, "pykoi.rlhf.rlhf.SFT.train"]], "train_and_save() (pykoi.rlhf.rlhf.rewardtrainer method)": [[8, "pykoi.rlhf.rlhf.RewardTrainer.train_and_save"]], "train_and_save() (pykoi.rlhf.rlhf.sft method)": [[8, "pykoi.rlhf.rlhf.SFT.train_and_save"]], "train_test_split_ratio (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.train_test_split_ratio"]], "trainer (pykoi.rlhf.rlhf.sft attribute)": [[8, "pykoi.rlhf.rlhf.SFT.trainer"]], "training_args (pykoi.rlhf.rlhf.sft attribute)": [[8, "pykoi.rlhf.rlhf.SFT.training_args"]], "weight_decay (pykoi.rlhf.rlhf.rlhfconfig attribute)": [[8, "pykoi.rlhf.rlhf.RLHFConfig.weight_decay"]]}})